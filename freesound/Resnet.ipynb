{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.core import *\n",
    "from fastai.io import *\n",
    "from fastai.dataloader import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.learner import *\n",
    "from fastai.models.resnet import *\n",
    "import os\n",
    "from audio_dataset import *\n",
    "from audio_transforms import *\n",
    "\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from librosa import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/freesound')\n",
    "TRN_PATH = PATH/'audio_train'\n",
    "TEST_PATH = PATH/'audio_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = pd.read_csv(PATH/'train.csv')\n",
    "test = pd.read_csv(PATH/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "verified = list(trn['manually_verified'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00044347.wav</td>\n",
       "      <td>Hi-hat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001ca53d.wav</td>\n",
       "      <td>Saxophone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002d256b.wav</td>\n",
       "      <td>Trumpet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0033e230.wav</td>\n",
       "      <td>Glockenspiel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00353774.wav</td>\n",
       "      <td>Cello</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname         label\n",
       "0  00044347.wav        Hi-hat\n",
       "1  001ca53d.wav     Saxophone\n",
       "2  002d256b.wav       Trumpet\n",
       "3  0033e230.wav  Glockenspiel\n",
       "4  00353774.wav         Cello"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn = trn[['fname','label']].copy()\n",
    "trn_sample = trn[:1900]\n",
    "trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn.to_csv('trn.csv', index=False)\n",
    "trn_sample.to_csv('trn_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9473, 41)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.shape[0], len(trn.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9473, 9400)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames = list(trn['fname']) \n",
    "test_fnames = list(test['fname']) \n",
    "len(fnames), len(test_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_wavs = (PATH/'audio_train').glob('*.wav')\n",
    "test_wavs = (PATH/'audio_test').glob('*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = (np.array([ 0.18637]), np.array([ 0.30634]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listen to Sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = list(test.label[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length= int(3*44100) #seconds * sample_rate\n",
    "n = 4\n",
    "\n",
    "#play sample with stats\n",
    "#length = 3*44100\n",
    "#sample = os.path.join(TRN_PATH, fnames[n])\n",
    "sample = os.path.join(TEST_PATH, test_fnames[n])\n",
    "print(test_fnames[n])\n",
    "raw = open_audio(sample)\n",
    "raw_len = len(raw)\n",
    "raw_s = adj_length(raw, length)\n",
    "#print('raw length: ', raw_len, 'sample length:', len(raw_s))\n",
    "#print('label:', trn['label'].iloc[n], 'verified:', verified[n])\n",
    "print('prediction:', test_preds[n])\n",
    "ipd.Audio(raw_s, rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio_transforms\n",
    "\n",
    "Transforms taken from Fastai's `transforms.py` and modified to work with Audio files. *Not shown because competition is still in progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "class Transform():\n",
    "    \"\"\" A class that represents a transform.\n",
    "\n",
    "    All other transforms should subclass it. All subclasses should override\n",
    "    do_transform.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "        tfm_y : TfmType\n",
    "            type of transform\n",
    "    \"\"\"\n",
    "    def __init__(self, tfm_y=TfmType.NO):\n",
    "        self.tfm_y=tfm_y\n",
    "        self.store = threading.local()\n",
    "\n",
    "    def set_state(self): pass\n",
    "    def __call__(self, x, y):\n",
    "        self.set_state()\n",
    "        x,y = ((self.transform(x),y) if self.tfm_y==TfmType.NO\n",
    "                else self.transform(x,y) if self.tfm_y in (TfmType.PIXEL, TfmType.CLASS)\n",
    "                else self.transform_coord(x,y))\n",
    "        return x, y\n",
    "\n",
    "    def transform_coord(self, x, y): return self.transform(x),y\n",
    "\n",
    "    def transform(self, x, y=None):\n",
    "        x = self.do_transform(x,False)\n",
    "        return (x, self.do_transform(y,True)) if y is not None else x\n",
    "\n",
    "    @abstractmethod\n",
    "    def do_transform(self, x, is_y): raise NotImplementedError\n",
    "\n",
    "\n",
    "class Denormalize():\n",
    "    \"\"\" De-normalizes an image, returning it to original format.\n",
    "    \"\"\"\n",
    "    def __init__(self, m, s):\n",
    "        self.m=np.array(m, dtype=np.float32)\n",
    "        self.s=np.array(s, dtype=np.float32)\n",
    "    def __call__(self, x): return x*self.s+self.m\n",
    "\n",
    "\n",
    "class Normalize():\n",
    "    \"\"\" Normalizes an image to zero mean and unit standard deviation, given the mean m and std s of the original image \"\"\"\n",
    "    def __init__(self, m, s): #tfm_y=TfmType.NO\n",
    "        self.m=np.array(m, dtype=np.float32)\n",
    "        self.s=np.array(s, dtype=np.float32)\n",
    "        #self.tfm_y=tfm_y\n",
    "\n",
    "    def __call__(self, x, y=None):\n",
    "        x = (x-self.m)/self.s\n",
    "        #if self.tfm_y==TfmType.PIXEL and y is not None: y = (y-self.m)/self.s\n",
    "        return x,y\n",
    "\n",
    "class ChannelOrder():\n",
    "    '''\n",
    "    changes image array shape from (h, w, 3) to (3, h, w). \n",
    "    tfm_y decides the transformation done to the y element. \n",
    "    '''\n",
    "    def __init__(self, tfm_y=TfmType.NO): self.tfm_y=tfm_y\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        x = np.rollaxis(x, 2)\n",
    "        #if isinstance(y,np.ndarray) and (len(y.shape)==3):\n",
    "        #if self.tfm_y==TfmType.PIXEL: y = np.rollaxis(y, 2)\n",
    "        #elif self.tfm_y==TfmType.CLASS: y = y[...,0]\n",
    "        return x,y\n",
    "\n",
    "def vocode(x,y,rate=2.0):\n",
    "    return librosa.phase_vocoder(x, rate), y\n",
    "\n",
    "def rand0(s): return random.random()*(s*2)-s\n",
    "\n",
    "def rand1(s): return int(random.random()*s)\n",
    "\n",
    "def focus_mel(aud, b, c):\n",
    "    ''' highlights audio's mel_bands'''\n",
    "    if b == 0: return aud\n",
    "    mu = np.average(aud[:b])\n",
    "    return aud[:b]+mu*c\n",
    "\n",
    "class RandomFocus_mel(Transform):\n",
    "    def __init__(self, b, c, tfm_y=TfmType.NO):\n",
    "        super().__init__(tfm_y)\n",
    "        self.b,self.c = b,c\n",
    "        \n",
    "    def set_state(self):\n",
    "        self.store.b_rand = rand1(self.b)\n",
    "        self.store.c_rand = self.c\n",
    "        \n",
    "    def do_transform(self, x, is_y):\n",
    "        b = self.store.b_rand\n",
    "        c = self.store.c_rand\n",
    "        x = focus_mel(x, b, c)\n",
    "        return x\n",
    "\n",
    "def lighting(im, b, c):\n",
    "    ''' adjusts image's balance and contrast'''\n",
    "    if b==0 and c==1: return im\n",
    "    mu = np.average(im)\n",
    "    return np.clip((im-mu)*c+mu+b,0.,1.).astype(np.float32)\n",
    "\n",
    "class RandomLighting(Transform):\n",
    "    def __init__(self, b, c, tfm_y=TfmType.NO):\n",
    "        super().__init__(tfm_y)\n",
    "        self.b,self.c = b,c\n",
    "\n",
    "    def set_state(self):\n",
    "        self.store.b_rand = rand0(self.b)\n",
    "        self.store.c_rand = rand0(self.c)\n",
    "\n",
    "    def do_transform(self, x, is_y):\n",
    "        #if is_y and self.tfm_y != TfmType.PIXEL: return x\n",
    "        b = self.store.b_rand\n",
    "        c = self.store.c_rand\n",
    "        c = -1/(c-1) if c<0 else c+1\n",
    "        x = lighting(x, b, c)\n",
    "        return x\n",
    "       \n",
    "def compose(im, y, fns):\n",
    "    \"\"\" apply a collection of transformation functions fns to images\n",
    "    \"\"\"\n",
    "    for fn in fns:\n",
    "        #pdb.set_trace()\n",
    "        im, y =fn(im, y)\n",
    "    return im if y is None else (im, y)\n",
    "\n",
    "\n",
    "class Transforms():\n",
    "    def __init__(self, sz, tfms, normalizer, denorm, crop_type=CropType.CENTER,\n",
    "                 tfm_y=TfmType.NO, sz_y=None):\n",
    "        if sz_y is None: sz_y = sz\n",
    "        self.sz,self.denorm,self.norm,self.sz_y = sz,denorm,normalizer,sz_y\n",
    "        crop_tfm = crop_fn_lu[crop_type](sz, tfm_y, sz_y)\n",
    "        self.tfms = tfms\n",
    "        self.tfms.append(crop_tfm)\n",
    "        if normalizer is not None: self.tfms.append(normalizer)\n",
    "        self.tfms.append(ChannelOrder(tfm_y))\n",
    "\n",
    "    def __call__(self, im, y=None): return compose(im, y, self.tfms)\n",
    "    def __repr__(self): return str(self.tfms)\n",
    "\n",
    "\n",
    "def image_gen(normalizer, denorm, sz, tfms=None, max_zoom=None, pad=0, crop_type=None,\n",
    "              tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, scale=None):\n",
    "    \"\"\"\n",
    "    Generate a standard set of transformations\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "     normalizer :\n",
    "         image normalizing function\n",
    "     denorm :\n",
    "         image denormalizing function\n",
    "     sz :\n",
    "         size, sz_y = sz if not specified.\n",
    "     tfms :\n",
    "         iterable collection of transformation functions\n",
    "     max_zoom : float,\n",
    "         maximum zoom\n",
    "     pad : int,\n",
    "         padding on top, left, right and bottom\n",
    "     crop_type :\n",
    "         crop type\n",
    "     tfm_y :\n",
    "         y axis specific transformations\n",
    "     sz_y :\n",
    "         y size, height\n",
    "     pad_mode :\n",
    "         cv2 padding style: repeat, reflect, etc.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "     type : ``Transforms``\n",
    "         transformer for specified image operations.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "     Transforms: the transformer object returned by this function\n",
    "    \"\"\"\n",
    "    if tfm_y is None: tfm_y=TfmType.NO\n",
    "    if tfms is None: tfms=[]\n",
    "    elif not isinstance(tfms, collections.Iterable): tfms=[tfms]\n",
    "    if sz_y is None: sz_y = sz\n",
    "    if scale is None:\n",
    "        scale = [RandomScale(sz, max_zoom, tfm_y=tfm_y, sz_y=sz_y) if max_zoom is not None\n",
    "                 else Scale(sz, tfm_y, sz_y=sz_y)]\n",
    "    elif not is_listy(scale): scale = [scale]\n",
    "    if pad: scale.append(AddPadding(pad, mode=pad_mode))\n",
    "    if crop_type!=CropType.GOOGLENET: tfms=scale+tfms\n",
    "    return Transforms(sz, tfms, normalizer, denorm, crop_type,\n",
    "                      tfm_y=tfm_y, sz_y=sz_y)\n",
    "\n",
    "def noop(x):\n",
    "    \"\"\"dummy function for do-nothing.\n",
    "    equivalent to: lambda x: x\"\"\"\n",
    "    return x\n",
    "\n",
    "class AudTransforms():\n",
    "    def __init__(self, tfms, normalizer, denorm):\n",
    "        #if sz_y is None: sz_y = sz\n",
    "        #self.sz,self.denorm,self.norm,self.sz_y = sz,denorm,normalizer,sz_y\n",
    "        self.denorm,self.norm = denorm,normalizer\n",
    "        #pdb.set_trace()\n",
    "        #crop_tfm = crop_fn_lu[crop_type](sz, tfm_y, sz_y)\n",
    "        self.tfms = tfms\n",
    "        #self.tfms.append(crop_tfm)\n",
    "        if normalizer is not None: self.tfms.append(normalizer)\n",
    "        #self.tfms.append(ChannelOrder())\n",
    "\n",
    "    def __call__(self, im, y=None): return compose(im, y, self.tfms) \n",
    "    def __repr__(self): return str(self.tfms)\n",
    "\n",
    "def audio_gen(normalizer, denorm, tfms=None):\n",
    "    if tfms is None: tfms = []\n",
    "    elif not isinstance(tfms, collections.Iterable): tfms=[tfms]\n",
    "    return AudTransforms(tfms, normalizer, denorm)\n",
    "\n",
    "def aud_tfms_from_stats(stats, aug_tfms=None):\n",
    "#def tfms_from_stats(stats, sz, aug_tfms=None, max_zoom=None, pad=0, crop_type=CropType.RANDOM,\n",
    "                    #tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, norm_y=True, scale=None):\n",
    "    \"\"\" Given the statistics of the training image sets, returns separate training and validation transform functions\n",
    "    \"\"\"\n",
    "    if aug_tfms is None: aug_tfms=[]\n",
    "    #tfm_norm = Normalize(*stats, tfm_y=tfm_y if norm_y else TfmType.NO) if stats is not None else None\n",
    "    tfm_norm = Normalize(*stats) if stats is not None else None\n",
    "    tfm_denorm = Denormalize(*stats) if stats is not None else None\n",
    "    #val_crop = CropType.CENTER if crop_type in (CropType.RANDOM,CropType.GOOGLENET) else crop_type\n",
    "    #val_tfm = image_gen(tfm_norm, tfm_denorm, sz, pad=pad, crop_type=val_crop,\n",
    "            #tfm_y=tfm_y, sz_y=sz_y, scale=scale)\n",
    "    val_tfm = audio_gen(tfm_norm, tfm_denorm)\n",
    "    #trn_tfm = image_gen(tfm_norm, tfm_denorm, sz, pad=pad, crop_type=crop_type,\n",
    "            #tfm_y=tfm_y, sz_y=sz_y, tfms=aug_tfms, max_zoom=max_zoom, pad_mode=pad_mode, scale=scale)\n",
    "    trn_tfm = audio_gen(tfm_norm, tfm_denorm, tfms=aug_tfms)\n",
    "    return trn_tfm, val_tfm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet\n",
    "\n",
    "Fastai's ResNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "\n",
    "def conv(ni, nf, ks=3, stride=1):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=False)\n",
    "\n",
    "\n",
    "def bn1(planes):\n",
    "    m = nn.BatchNorm1d(planes)\n",
    "    m.weight.data.fill_(1)\n",
    "    m.bias.data.zero_()\n",
    "    return m\n",
    "\n",
    "def bn(planes, init_zero=False):\n",
    "    m = nn.BatchNorm2d(planes)\n",
    "    m.weight.data.fill_(0 if init_zero else 1)\n",
    "    m.bias.data.zero_()\n",
    "    return m\n",
    "\n",
    "class fc1(nn.Module):\n",
    "    def __init__(self, ni, nf, ks=2, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ni,nf,kernel_size=ks,stride=stride, padding=padding)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.max = nn.MaxPool2d(2, stride=2, padding=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.conv(x)\n",
    "        #return self.relu(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.max(out)\n",
    "        return out\n",
    "\n",
    "class fc2(nn.Module):\n",
    "    def __init__(self, ni, nf, ks=1, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ni,nf,kernel_size=ks,stride=stride)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        #self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.conv(x)\n",
    "        return self.sigmoid(out)\n",
    "        #return self.relu(out)\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super().__init__()\n",
    "        self.lambd = lambd\n",
    "    def forward(self, x):\n",
    "        #pdb.set_trace()\n",
    "        return self.lambd(x)\n",
    "    \n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv(inplanes, planes, stride=stride)\n",
    "        self.bn1 = bn(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv(planes, planes)\n",
    "        self.bn2 = bn(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        if self.downsample is not None: residual = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.bn1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = residual + out\n",
    "        out = self.relu(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "class MyResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=1000, k=1, vgg_head=False):\n",
    "        super().__init__()\n",
    "        self.inplanes = 64\n",
    "\n",
    "        features = [conv(1, 64, ks=7, stride=2)\n",
    "            , bn(64) , nn.ReLU(inplace=True) , nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "            , self._make_layer(block, int(64*k), layers[0])\n",
    "            , self._make_layer(block, int(128*k), layers[1], stride=2)\n",
    "            , self._make_layer(block, int(256*k), layers[2], stride=2)\n",
    "            , self._make_layer(block, int(512*k), layers[3], stride=2)]\n",
    "        out_sz = int(512*k) * block.expansion\n",
    "\n",
    "        if vgg_head:\n",
    "            features += [nn.AdaptiveAvgPool2d(3), Flatten()\n",
    "                , nn.Linear(out_sz*3*3, 4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n",
    "                , nn.Linear(4096,   4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n",
    "                , nn.Linear(4096, num_classes)]\n",
    "        else: features += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(out_sz, num_classes)]\n",
    "        \n",
    "        self.features = nn.Sequential(*features)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv(self.inplanes, planes*block.expansion, ks=1, stride=stride),\n",
    "                bn(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks): layers.append(block(self.inplanes, planes))\n",
    "        return nn.Sequential(*layers)#, nn.Dropout2d(0.5))\n",
    "\n",
    "    def forward(self, x): return self.features(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from John Hartquist\n",
    "def mapk_np(preds, targs, k=3):\n",
    "    preds = np.argsort(-preds, axis=1)[:, :k]\n",
    "    score = 0.0\n",
    "    for i in range(k):\n",
    "        num_hits = (preds[:, i] == targs).sum()\n",
    "        score += num_hits * (1.0 / (i+1.0))\n",
    "    score /= preds.shape[0]\n",
    "    return score\n",
    "\n",
    "def mapk(preds, targs, k=3):\n",
    "    return mapk_np(to_np(preds), to_np(targs), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def B6(ni,nf):\n",
    "    return nn.Sequential(\n",
    "        conv(ni,nf), \n",
    "        bn(nf), \n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(2,2,padding=1))\n",
    "\n",
    "class AudioCNN(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super().__init__()\n",
    "        #self.num_classes = num_classes\n",
    "\n",
    "        features = [BasicBlock(1,16), BasicBlock(16,32), BasicBlock(32,64),\n",
    "                    BasicBlock(64,128), BasicBlock(128,256), B6(256,512),\n",
    "                    fc1(512,1024), fc2(1024,num_classes), \n",
    "                    Lambda(lambda x: x.view(x.shape[0], 41, -1)), \n",
    "                    Lambda(lambda x: torch.mean(x, dim=2))]\n",
    "        \n",
    "        self.features = nn.Sequential(*features)\n",
    "        \n",
    "    def forward(self, x): return self.features(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = aud_tfms_from_stats(stats, aug_tfms=[RandomLighting(0.5,0.5)])\n",
    "md = AudioClassifierData.from_csv(PATH, 'audio_train', 'trn.csv', val_idxs=1, bs=32, tfms=tfms, test_name='audio_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MyResNet(BasicBlock, [3, 4, 6, 3], num_classes=41, vgg_head=False)\n",
    "opt = optim.Adam\n",
    "metrics = [accuracy, mapk]\n",
    "loss = F.cross_entropy\n",
    "learn = ConvLearner.from_model_data(m, md, crit=loss, metrics=metrics, opt_fn=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-4, 1, wds=1e-5, cycle_len=20, use_clr_beta=(5,20,0.95,0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('2d_res_1ch_hop25610s_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('2d_res_1ch_hop25610s_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.697, Val MAP: 0.770\n"
     ]
    }
   ],
   "source": [
    "learn.model.eval()\n",
    "val_preds = learn.predict_with_targs()\n",
    "\n",
    "val_acc = accuracy_np(*val_preds)\n",
    "val_map = mapk_np(*val_preds)\n",
    "\n",
    "print(f'Val Acc: {val_acc:.3f}, Val MAP: {val_map:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              \r"
     ]
    }
   ],
   "source": [
    "multi_preds, y = learn.TTA(is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.mean(multi_preds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(PATH/'tmp/preds14.npy', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trumpet Saxophone Oboe',\n",
       " 'Hi-hat Chime Shatter',\n",
       " 'Cello Double_bass Acoustic_guitar',\n",
       " 'Trumpet Violin_or_fiddle Meow',\n",
       " 'Bass_drum Knock Gunshot_or_gunfire']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.array(sorted(trn.label.unique()))\n",
    "top_3_idx = [np.argsort(preds[i])[-3:][::-1] for i in range(len(test_fnames))]\n",
    "pred_labels = [list(classes[[top_3_idx[i]]]) for i in range(len(test_fnames))]\n",
    "preds = [\" \".join(ls) for ls in pred_labels]\n",
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tested = [md.test_ds.fnames[i].split('/')[-1] for i in range(len(test_fnames))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "for fname in test_fnames:\n",
    "    for name in tested:\n",
    "        if name == fname:\n",
    "            idx.append(tested.index(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00063640.wav',\n",
       " '0013a1db.wav',\n",
       " '002bb878.wav',\n",
       " '002d392d.wav',\n",
       " '00326aa9.wav']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tested[i] for i in idx[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00063640.wav',\n",
       " '0013a1db.wav',\n",
       " '002bb878.wav',\n",
       " '002d392d.wav',\n",
       " '00326aa9.wav']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fnames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'] = [preds[i] for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00063640.wav</td>\n",
       "      <td>Shatter Tearing Fireworks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0013a1db.wav</td>\n",
       "      <td>Flute Oboe Trumpet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002bb878.wav</td>\n",
       "      <td>Bass_drum Computer_keyboard Knock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002d392d.wav</td>\n",
       "      <td>Bass_drum Flute Cello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00326aa9.wav</td>\n",
       "      <td>Oboe Clarinet Telephone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname                              label\n",
       "0  00063640.wav          Shatter Tearing Fireworks\n",
       "1  0013a1db.wav                 Flute Oboe Trumpet\n",
       "2  002bb878.wav  Bass_drum Computer_keyboard Knock\n",
       "3  002d392d.wav              Bass_drum Flute Cello\n",
       "4  00326aa9.wav            Oboe Clarinet Telephone"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(PATH/'tmp/sub13.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9400, 2)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "deeplearning/freesound/freesound.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
